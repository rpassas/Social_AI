{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import itertools as it\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from agents.agent import Agent\n",
    "from agents.utils.utility import sigmoid_update #, linear_update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea\n",
    "If I have a good estimate of your prior and of your error, can I learn your internal model M across time steps?\n",
    "<br/>\n",
    "Let's start by assuming I have a perfect estimate of your priors and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97798951]\n"
     ]
    }
   ],
   "source": [
    "# agent\n",
    "a = Agent(state_size=1, model_var=0, prediction=\"sigmoid\", behavior=\"sigmoid\", attention=\"static\", seed=7)\n",
    "# error the agent is being fed\n",
    "time = 20\n",
    "#noise = np.random.uniform(0,1,50)\n",
    "#print(noise)\n",
    "#e_in = np.linspace(1, 0.1, time)\n",
    "#e_in = e_in * noise\n",
    "#print(e_in)\n",
    "print(a.get_behav_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behaviors:  [1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "behaviors = np.random.choice([0, 1], size=(time,), p=[1./3, 2./3])\n",
    "print(\"behaviors: \", behaviors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors:  [0.614421736848592, -0.5370530390093043, -0.40406191104371686, 0.6883958886461468]\n",
      "priors:  [0.8442932825298948, 0.9081642599612204, 0.8539834046210683, 0.7975454113975015]\n"
     ]
    }
   ],
   "source": [
    "# for each time step, send a behavior, get a prior, get error\n",
    "errors = []\n",
    "priors = []\n",
    "m_hat = 0.5\n",
    "for t in range(time):\n",
    "    bp = a.get_behav_priors()\n",
    "    priors.append(bp[0])\n",
    "    a.get_world([behaviors[t]])\n",
    "    dif, avg_abs_error = a.behavior_prediction_error()\n",
    "    errors.append(dif[0])\n",
    "    a.learn_conform()\n",
    "    a.learn_predict_world()\n",
    "print(\"errors: \", errors[:4])\n",
    "print(\"priors: \", priors[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets find the M to minimize the derivative of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(m, X, Y, learning_rate):\n",
    "    m_deriv = 0\n",
    "    #b_deriv = 0\n",
    "    N = len(X)\n",
    "    for i in range(N-1):\n",
    "        # Calculate partial derivatives\n",
    "        # -2x(y - (mx + b))\n",
    "        #m_deriv += -2*X[i] * (Y[i+1] - (m*X[i]+Y[i]))\n",
    "        e = X[i]*m\n",
    "        m_deriv -= ( (2*m*(1-Y[i])*np.exp(-e)) * (Y[i+1]-(1 / ((((1-Y[i])*np.exp(-e))/Y[i]) + 1))) / (Y[i]*( ((((1-Y[i])*np.exp(-e))/Y[i]) + 1) ** 2)) )\n",
    "        #m_deriv += sigmoid_update(prev=Y[i], error=[e])\n",
    "\n",
    "        # -2(y - (mx + b))\n",
    "        #b_deriv += -2*(Y[i] - (m*X[i] + b))\n",
    "\n",
    "    # We subtract because the derivatives point in direction of steepest ascent\n",
    "    m -= (m_deriv / float(N-1)) * learning_rate\n",
    "    #b -= (b_deriv / float(N)) * learning_rate\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_hat:  0.5000719188695288\n",
      "m:  [0.97798951]\n"
     ]
    }
   ],
   "source": [
    "m_hat = update_weights(m_hat, errors, priors, .5)\n",
    "m = a.get_behav_model()\n",
    "print(\"m_hat: \", m_hat)\n",
    "#print(\"b: \", b)\n",
    "print(\"m: \", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Experiment\n",
    "For the sake of simplicity, let's make some new assumptions:\n",
    "\n",
    "1. priors are determined by a function at each time step that is always centered around the same set point/intercept\n",
    "2. the prior function is linear, rather than a sigmoid\n",
    "3. M is a coefficent of error and the prior is the intercept = new prior\n",
    "4. for this experiment let's initially assume we have access to the prior of the other agent and are just trying to estimate their prior function\n",
    "\n",
    "Why do this?\n",
    "\n",
    "1. simpler estimation of latent variables M and B\n",
    "2. can more eeffectivelly use conjugate priors to estimate B (beta distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_update(B, M, X):\n",
    "    Xt = M*X + B\n",
    "    if Xt > 1:\n",
    "        return 1\n",
    "    if Xt < 0:\n",
    "        return 0\n",
    "    return Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors:   [0.77951526]\n",
      "base priors:  [0.84129035]\n",
      "M:  [-0.04139652]\n"
     ]
    }
   ],
   "source": [
    "time = 1\n",
    "state_size = 1\n",
    "# for each time step, send a behavior, get a prior, get error\n",
    "errors = np.linspace(0.9,0.1,time)\n",
    "noise = np.random.uniform(0.7,0.9,time)\n",
    "errors = errors * noise\n",
    "print(\"errors:  \", errors)\n",
    "base_priors = np.random.uniform(0.1,0.9,state_size)\n",
    "print(\"base priors: \", base_priors)\n",
    "M = np.random.uniform(-0.5,0.5,state_size)\n",
    "print(\"M: \", M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior:  [0.8090211310389682]\n"
     ]
    }
   ],
   "source": [
    "priors = []\n",
    "for t in range(time):\n",
    "    p = linear_update(base_priors[t], M[0], errors[t])\n",
    "    priors.append(p)\n",
    "print(\"prior: \",priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = (base_prior - new_prior) / error\n",
      "-0.041396520232030665 = 0.8412903502160453 - 0.8090211310389682 / 0.7795152586788848\n"
     ]
    }
   ],
   "source": [
    "# I know the base prior from past time steps, the error because I assume it based on my prior, and I see your current prior\n",
    "print(\"M = (base_prior - new_prior) / error\")\n",
    "print(f\"{M[0]} = {base_priors[0]} - {priors[0]} / {errors[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Assumptions\n",
    "Now let's assume we do not have access to the priors (base and updates).\n",
    "\n",
    "Can we still estimate M?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some pre-computed errors:   [ 0.57662601 -0.68913246 -0.70967203  0.21472195  0.6282052 ]\n",
      "base priors:  [0.46884247 0.81352518]\n",
      "Ms:  [-0.16332414 -0.30749217]\n"
     ]
    }
   ],
   "source": [
    "time = 100\n",
    "state_size = 2\n",
    "# for each time step, send a behavior, get a prior, get error\n",
    "errors = np.linspace(0.9,0.1,time)\n",
    "noise = np.random.uniform(-0.9,0.9,time)\n",
    "errors = errors * noise\n",
    "base_priors = np.random.uniform(0.1,0.9,state_size)\n",
    "print(\"some pre-computed errors:  \", errors[:5])\n",
    "print(\"base priors: \", base_priors)\n",
    "M = np.random.uniform(-0.5,0.5,state_size)\n",
    "print(\"Ms: \", M)\n",
    "\n",
    "\n",
    "behaviors = []\n",
    "for t in range(time):\n",
    "    step = []\n",
    "    for s in range(state_size):\n",
    "        p = linear_update(base_priors[s], M[s], errors[s])\n",
    "        behavior = np.random.binomial(1, p)\n",
    "        step.append(behavior)\n",
    "    behaviors.append(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 0, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.5, 0.5]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [0, 0]\n",
      "T: 10, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.42857142857142855, 0.8571428571428571]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [0.03054985502798218, 0.026640404691239086]\n",
      "T: 20, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.375, 0.9166666666666666]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [-0.09997399809837405, 0.028723942057164945]\n",
      "T: 30, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.38235294117647056, 0.9411764705882353]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [-0.6424970326060622, -0.040734552955389726]\n",
      "T: 40, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.36363636363636365, 0.9545454545454546]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [-0.6715184448978089, -0.04355363293603015]\n",
      "T: 50, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.35185185185185186, 0.9629629629629629]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [-0.8493315804563848, -0.08041787132837674]\n",
      "T: 60, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.359375, 0.96875]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [-0.9870731225151194, -0.04359976502200564]\n",
      "T: 70, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.3783783783783784, 0.972972972972973]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [-0.9407576356878384, -0.2226758769787522]\n",
      "T: 80, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.39285714285714285, 0.9761904761904762]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [-0.9446968151936639, -0.2296546348990411]\n",
      "T: 90, True Priors: [0.46884247 0.81352518], Posterior Estimate: [0.3829787234042553, 0.9787234042553191]\n",
      "True M: [-0.16332414 -0.30749217], M Estimate: [-0.8867053348989392, -0.20984862407260352]\n"
     ]
    }
   ],
   "source": [
    "# get an estimate of the base priors\n",
    "a = [2]*state_size\n",
    "b = [2]*state_size\n",
    "mode = [0.5]*state_size\n",
    "m_hat = [0]*state_size\n",
    "buckets = [{} for s in range(state_size)]\n",
    "alpha = 0.01\n",
    "\n",
    "for t in range(time):\n",
    "    if t % 10 == 0:\n",
    "        print(f\"T: {t}, True Priors: {base_priors}, Posterior Estimate: {mode}\")\n",
    "        print(f\"True M: {M}, M Estimate: {m_hat}\")\n",
    "        print(\"\\n\")\n",
    "    for s in range(state_size):\n",
    "        a[s] = a[s]+behaviors[t][s]\n",
    "        b[s] = b[s]-behaviors[t][s]+1\n",
    "        mode[s] = a[s]/(a[s]+b[s])\n",
    "        if round(errors[t], 1) in buckets[s]:\n",
    "            buckets[s][round(errors[t], 1)].append(behaviors[t][s])\n",
    "        else:\n",
    "            buckets[s][round(errors[t], 1)] = [behaviors[t][s]]\n",
    "        a_post = sum(buckets[s][round(errors[t], 1)])\n",
    "        b_post = len(buckets[s][round(errors[t], 1)])-a_post\n",
    "        mode_post = a_post/(a_post+b_post)\n",
    "        m_hat[s] = (((mode_post - mode[s]) / errors[t]) * alpha) + m_hat[s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0, True Priors: [0.44036742 0.29804642], Estimates: [0.5, 0.5]\n",
      "Time: 10, True Priors: [0.44036742 0.29804642], Estimates: [0.5714285714285714, 0.14285714285714285]\n",
      "Time: 20, True Priors: [0.44036742 0.29804642], Estimates: [-0.1125, 0.0]\n",
      "Time: 30, True Priors: [0.44036742 0.29804642], Estimates: [-0.08536585365853659, 0.0]\n",
      "Time: 40, True Priors: [0.44036742 0.29804642], Estimates: [-0.09876543209876543, 0.0]\n",
      "Time: 50, True Priors: [0.44036742 0.29804642], Estimates: [-0.1125, 0.0]\n",
      "Time: 60, True Priors: [0.44036742 0.29804642], Estimates: [-0.09876543209876543, 0.0]\n",
      "Time: 70, True Priors: [0.44036742 0.29804642], Estimates: [-0.08536585365853659, 0.0]\n",
      "Time: 80, True Priors: [0.44036742 0.29804642], Estimates: [-0.05952380952380952, 0.0]\n",
      "Time: 90, True Priors: [0.44036742 0.29804642], Estimates: [-0.05952380952380952, 0.0]\n",
      "Time: 100, True Priors: [0.44036742 0.29804642], Estimates: [-0.09876543209876543, 0.0]\n",
      "Time: 110, True Priors: [0.44036742 0.29804642], Estimates: [-0.07228915662650602, 0.0]\n",
      "Time: 120, True Priors: [0.44036742 0.29804642], Estimates: [-0.1125, 0.0]\n",
      "Time: 130, True Priors: [0.44036742 0.29804642], Estimates: [-0.08536585365853659, 0.0]\n",
      "Time: 140, True Priors: [0.44036742 0.29804642], Estimates: [-0.14102564102564102, 0.0]\n",
      "Time: 150, True Priors: [0.44036742 0.29804642], Estimates: [-0.12658227848101267, 0.0]\n",
      "Time: 160, True Priors: [0.44036742 0.29804642], Estimates: [-0.09876543209876543, 0.0]\n",
      "Time: 170, True Priors: [0.44036742 0.29804642], Estimates: [-0.08536585365853659, 0.0]\n",
      "Time: 180, True Priors: [0.44036742 0.29804642], Estimates: [-0.08536585365853659, 0.0]\n",
      "Time: 190, True Priors: [0.44036742 0.29804642], Estimates: [-0.05952380952380952, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# just curious to see what happens if we use memory\n",
    "a_m = [2]*state_size\n",
    "b_m = [2]*state_size\n",
    "mode_m = [0.5]*state_size\n",
    "mem = 15\n",
    "\n",
    "for t in range(time):\n",
    "    if t % 10 == 0:\n",
    "        print(f\"Time: {t}, True Priors: {base_priors}, Estimates: {mode_m}\")\n",
    "    for s in range(state_size):\n",
    "        if t > mem:\n",
    "            a_m[s] = sum([behaviors[i][s] for i in range(t, t-mem, -1)])\n",
    "            b_m[s] = mem-a[s]\n",
    "            mode_m[s] = a_m[s]/(a_m[s]+b_m[s])\n",
    "        else:\n",
    "            a_m[s] = a_m[s]+behaviors[t][s]\n",
    "            b_m[s] = b_m[s]-behaviors[t][s]+1\n",
    "            mode_m[s] = a_m[s]/(a_m[s]+b_m[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to estimate M given error and the estimated prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
